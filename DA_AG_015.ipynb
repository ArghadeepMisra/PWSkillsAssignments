{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Boosting Techniques | Assignment"
      ],
      "metadata": {
        "id": "k_OgBQUwxVQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Code: DA-AG-015"
      ],
      "metadata": {
        "id": "NYcvCHUuxWjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arghadeep Misra |\n",
        "+91 8250675419"
      ],
      "metadata": {
        "id": "7WGQoZm7xb2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CyBLqlZ_0cEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners."
      ],
      "metadata": {
        "id": "b0Kq_0D0xjAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "\n",
        "Boosting is an ensemble method. It combines many weak learners to make one strong learner. A weak learner is a model that does only a little better than random guessing. Boosting trains models one after another. Each new model focuses more on the mistakes of the previous ones.\n",
        "\n",
        "For example, in AdaBoost the algorithm increases the weight of wrong predictions so the next learner tries harder on them. In Gradient Boosting, each new learner is fitted on the errors left over from the earlier ones. At the end, all the learners are combined, often by weighted voting or adding their outputs.\n",
        "\n",
        "This step-by-step correction makes the final model more accurate than any single weak learner."
      ],
      "metadata": {
        "id": "WTwvPRBPxodx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "RSmeKwiD0cwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?"
      ],
      "metadata": {
        "id": "F7-7yfBexx5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "\n",
        "AdaBoost and Gradient Boosting are both boosting methods, but they train models in different ways.\n",
        "\n",
        "AdaBoost works by giving higher weights to the data points that were classified wrong by the previous model. The next weak learner focuses more on those hard cases. At the end, it combines all weak learners with weights based on their accuracy.\n",
        "\n",
        "Gradient Boosting does not use weights in the same way. Instead, it builds each new model on the residual errors of the previous models. The idea is that each new learner predicts the part the old ones missed. It uses gradient descent to reduce the loss function step by step.\n",
        "\n",
        "In short: AdaBoost adjusts weights of samples, Gradient Boosting reduces errors using gradients."
      ],
      "metadata": {
        "id": "z714J3SXx4JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JRxH606Z0bMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3 - How does regularization help in XGBoost?"
      ],
      "metadata": {
        "id": "3BQFcX6UyE4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "Regularization in XGBoost helps control overfitting. Overfitting happens when the model learns noise from training data instead of real patterns.\n",
        "\n",
        "XGBoost adds penalty terms to its objective function. These penalties control the complexity of trees. The L1 penalty (like Lasso) can make some weights zero, removing unnecessary features. The L2 penalty (like Ridge) reduces the size of weights, making the model more stable.\n",
        "\n",
        "By using these penalties, the model becomes simpler, more general, and performs better on new unseen data."
      ],
      "metadata": {
        "id": "hAlDlsoMyF5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "rhoYNfLB0aTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 - Why is CatBoost considered efficient for handling categorical data?"
      ],
      "metadata": {
        "id": "Jm_A-IR1yIfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "CatBoost is designed to work well with categorical features. Normally, models need categorical values to be converted into numbers using one-hot encoding or label encoding. These methods can make the dataset very large or add noise.\n",
        "\n",
        "CatBoost avoids this by using a special technique called target-based encoding with random permutations. It turns categories into numerical values while reducing the risk of overfitting. It also handles high-cardinality features, where there are many unique categories, without making the dataset explode in size.\n",
        "\n",
        "Because of this built-in method, CatBoost saves preprocessing time and improves performance when data has many categorical variables."
      ],
      "metadata": {
        "id": "KBCV_D3kyMHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "yJkeUVH40Zur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5 - What are some real-world applications where boosting techniques are preferred over bagging methods?"
      ],
      "metadata": {
        "id": "vOppdUPZyPWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "Boosting is often better than bagging when small improvements in accuracy are important.\n",
        "\n",
        "Finance - Boosting models are used to detect fraud in credit card transactions where small errors can cost a lot.\n",
        "\n",
        "Healthcare - Boosting is applied in predicting diseases from medical records. The step-by-step corrections improve sensitivity.\n",
        "\n",
        "Marketing - Companies use boosting to predict customer churn and buying behavior more accurately.\n",
        "\n",
        "Online platforms - Boosting helps in ranking search results and recommending products.\n",
        "\n",
        "Risk management - Banks use boosting to assess loan default chances with better precision.\n",
        "\n",
        "In these areas, boosting is preferred because it reduces bias and catches complex patterns that bagging sometimes misses."
      ],
      "metadata": {
        "id": "6ys1XJ44ySc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "42RVXGG80Y6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6 - Write a Python program to train an AdaBoost Classifier on the Breast Cancer dataset and print the model accuracy."
      ],
      "metadata": {
        "id": "iih4ccudyXA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = AdaBoostClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFUiAVBRyZ_Y",
        "outputId": "fae8ce3c-7e2d-49f0-8972-03923fd13066"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "599jMCxA0Xzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7 - Write a Python program to train a Gradient Boosting Regressor on the California Housing dataset and evaluate performance using R-squared score."
      ],
      "metadata": {
        "id": "Amtd5eeZyfAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "reg_model = GradientBoostingRegressor(random_state=42)\n",
        "reg_model.fit(X_train, y_train)\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4acNHwlykH3",
        "outputId": "85e0a916-d3a1-4929-f7b6-a6d338b8f807"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.7756446042829697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "gCh8ZTLs0XK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8 - Write a Python program to train an XGBoost Classifier on the Breast Cancer dataset, tune the learning rate using GridSearchCV, and print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "gDce0iRbyhOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2]}\n",
        "grid = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKqRNGizytmF",
        "outputId": "ab69455e-b2f8-4e20-8c25-e352bb646083"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'learning_rate': 0.1}\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZTDx5noO0WaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9 - Write a Python program to train a CatBoost Classifier and plot the confusion matrix using seaborn."
      ],
      "metadata": {
        "id": "pBJ5Nw2wzJEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dtc9e7XzupF",
        "outputId": "5673754c-3a6e-4900-bd5e-cc41cc55ea3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = CatBoostClassifier(verbose=0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "fl4X9r_LzLs1",
        "outputId": "e7fd2bf0-17d8-4c79-91b6-076be78eae98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "0yCpoj2P0TbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10 - You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, has missing values, and includes both numeric and categorical features. Describe your step-by-step data science pipeline using boosting techniques."
      ],
      "metadata": {
        "id": "Tz4bina_0Cg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer -\n",
        "\n",
        "\n",
        "1/ Data preprocessing\n",
        "\n",
        "2/ Handle missing values: use mean/median for numeric columns, most frequent for categorical.\n",
        "\n",
        "3/ Encode categorical features: CatBoost can handle them directly, while XGBoost/AdaBoost need one-hot or label encoding.\n",
        "\n",
        "4/ Scale numeric values if needed, but boosting models usually work fine without scaling.\n",
        "\n",
        "5/ Model choice\n",
        "\n",
        "6/ CatBoost is a strong option because it handles categorical data well.\n",
        "\n",
        "7/ If the dataset has many numeric features and fewer categories, XGBoost is also a good choice.\n",
        "\n",
        "8/ AdaBoost is simpler, but less powerful for large complex datasets.\n",
        "\n",
        "9/ Hyperparameter tuning\n",
        "\n",
        "10/ Use GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "11/ Tune learning_rate, max_depth, n_estimators.\n",
        "\n",
        "12/ Use cross-validation to avoid overfitting.\n",
        "\n",
        "13/ Evaluation metrics\n",
        "\n",
        "14/ Since the dataset is imbalanced, accuracy is not enough.\n",
        "\n",
        "15/ Use metrics like F1-score, Precision, Recall, and especially AUC-ROC to judge performance.\n",
        "\n",
        "=> Business benefit\n",
        "\n",
        "=> The model helps the company reduce risk by identifying high default probability customers early.\n",
        "\n",
        "=> This allows smarter loan approvals, better credit scoring, and lower financial losses.\n",
        "\n",
        "=> It also helps in offering safer products to reliable customers."
      ],
      "metadata": {
        "id": "K-fcG2m_0D62"
      }
    }
  ]
}