{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics Advance Part 1 Assignment"
      ],
      "metadata": {
        "id": "6VzMepHKPXU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Arghadeep Misra"
      ],
      "metadata": {
        "id": "7gPbENKSPXR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Questions"
      ],
      "metadata": {
        "id": "uJoFBN7pPXPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is a random variable in probability theory?**"
      ],
      "metadata": {
        "id": "jbuuZPgSPXMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So a random variable is basically just a way to turn random events into numbers. Like when I flip a coin, instead of saying \"heads\" or \"tails\", I can say 1 for heads and 0 for tails. It makes the math easier because now I can calculate averages and stuff. The \"random\" part just means the outcome depends on chance."
      ],
      "metadata": {
        "id": "ENfVAwLkPXJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the types of random variables?**"
      ],
      "metadata": {
        "id": "kZnr4nQBPXHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2. What are the types of random variables?\n",
        "\n",
        "There are two types. Discrete random variables are for things you can count - like number of people, number of cars, etc. You get whole numbers. Continuous random variables are for things you measure - like height, weight, time. You can get any decimal value. So counting vs measuring basically."
      ],
      "metadata": {
        "id": "2AvPn2OHPXES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is the difference between discrete and continuous distributions?**"
      ],
      "metadata": {
        "id": "lB87qbJgPXBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OK so this builds on the previous answer. Discrete distributions are for countable stuff and continuous distributions are for measurable stuff. With discrete you can list out all possible values (like 1,2,3,4,5,6 for a die). With continuous you cant list them because there are infinite possibilities between any two numbers."
      ],
      "metadata": {
        "id": "Gj8BKl07PW-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What are probability distribution functions (PDF)?**"
      ],
      "metadata": {
        "id": "LPL_TE7iPW8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This is where it gets a bit tricky. PDF basically tells you how likely each outcome is. For discrete variables its straightforward - it gives you the exact probability of each value. For continuous variables its more complex because you cant have probability of exact values, so PDF gives you a \"density\" and you need to calculate areas under curves to get actual probabilities."
      ],
      "metadata": {
        "id": "CUsfWkdEPW5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?**"
      ],
      "metadata": {
        "id": "fi1-s9FKPW24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Think of CDF as a running total. While PDF tells you probability at each point, CDF tells you probability of getting that value OR anything less. So if I want to know probability of scoring 80 or less on a test, I use CDF. Its like adding up all the probabilities from the beginning up to that point."
      ],
      "metadata": {
        "id": "aplgVqHtPW0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is a discrete uniform distribution?**"
      ],
      "metadata": {
        "id": "NAUevIYSPWxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This one is actually pretty simple. Its when all outcomes have the same chance of happening. Like rolling a fair six-sided die - each number has 1/6 probability. Or picking a random day of the week - each day has 1/7 probability. Everything is equally likely."
      ],
      "metadata": {
        "id": "klbIMBPAPWuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What are the key properties of a Bernoulli distribution?**"
      ],
      "metadata": {
        "id": "_NlR_qflPWsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bernoulli distribution is really the foundation for understanding a lot of other distributions. Its for experiments that have exactly two outcomes - like flipping a coin (heads/tails), taking a test (pass/fail), or checking if a product is defective (yes/no).\n",
        "\n",
        "The key thing is there are only these two possibilities. If we call one outcome \"success\" with probability p, then the other outcome \"failure\" automatically has probability (1-p) since they have to add up to 1.\n",
        "\n",
        "The mean of a Bernoulli distribution is just p (the success probability), and the variance is p(1-p). What's interesting is that the variance is highest when p=0.5, meaning maximum uncertainty when both outcomes are equally likely."
      ],
      "metadata": {
        "id": "ibeMg8AmPWpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is the binomial distribution, and how is it used in probability?**"
      ],
      "metadata": {
        "id": "aVf97DHgPWmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Binomial distribution is basically what happens when you do multiple Bernoulli trials in a row.\n",
        "\n",
        "Like, if I flip a coin once, thats Bernoulli. But if I flip it 20 times and want to know the probability of getting exactly 12 heads, thats binomial.\n",
        "\n",
        "The key requirements are: fixed number of trials (n), each trial has same probability of success (p), and all trials are independent of each other.\n",
        "\n",
        "The formula gets a bit complex with combinations, but the idea is straightforward.\n",
        "\n",
        "Real world example: number of defective items in a batch, number of students passing an exam, or number of successful sales calls out of 100 attempts. The mean is np and variance is np(1-p)."
      ],
      "metadata": {
        "id": "ZASQPMJLPWj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is the Poisson distribution and where is it applied?**"
      ],
      "metadata": {
        "id": "eXeiyjrnPWg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Poisson distribution is really useful for modeling rare events that happen over time or space.\n",
        "\n",
        "The classic example is number of phone calls received at a call center per hour, or number of accidents at an intersection per month.\n",
        "\n",
        " What makes it Poisson is that events happen randomly but at some average rate (lambda), events are independent, and the probability of multiple events in a very small time period is essentially zero. Its great for quality control (defects per batch), biology (mutations per DNA sequence), or even website analytics (visits per minute).\n",
        "\n",
        " The interesting property is that both mean and variance equal lambda. So if average is 3 events per hour, variance is also 3"
      ],
      "metadata": {
        "id": "gG5rhwdAVNaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What is a continuous uniform distribution?**"
      ],
      "metadata": {
        "id": "NRekBYFpVNXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Continuous uniform distribution is like the \"fairest\" of all continuous distributions because every value in the range has exactly the same probability density.\n",
        "\n",
        "Imagine I'm picking a random number between 0 and 10 - every number like 3.7294 or 8.1556 has the same chance of being selected.\n",
        "\n",
        "The graph looks like a flat rectangle. This comes up in simulation studies, random number generation, or modeling situations where we truly have no reason to prefer any value over another within a range. The mean is simply the midpoint of the interval, and the variance depends on how wide the interval is. Its actually the maximum entropy distribution for a given range, which makes it the \"most random\" choice when we know nothing except the bounds."
      ],
      "metadata": {
        "id": "kZzWlSQdVNUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. What are the characteristics of a normal distribution?**"
      ],
      "metadata": {
        "id": "CP-OnhZQVNRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So the normal distribution is this bell-shaped curve that shows up everywhere, and I mean everywhere. The curve is perfectly symmetric - if you fold it down the middle it matches up exactly. Most of the data clusters around the center (the mean) and then it slopes off as you go to the extremes.\n",
        "\n",
        "There's this rule called 68-95-99.7 which basically means about 68% of values fall within 1 standard deviation of the mean, 95% within 2, and 99.7% within 3.\n",
        "\n",
        "So if you think about test scores or people's heights, most are close to average with fewer people at the really high or really low ends. The tails theoretically go on forever but they get so small they basically don't matter."
      ],
      "metadata": {
        "id": "R3uUmNZFVNO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the standard normal distribution, and why is it important?"
      ],
      "metadata": {
        "id": "HCGcbPr0VNL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The standard normal distribution is just any normal distribution that's been converted to have a mean of 0 and standard deviation of 1.\n",
        "\n",
        "Because once you standardize everything to this same scale, you can compare totally different things. Like I can compare my height (compared to other people my age) with my test score (compared to my classmates) by converting both to z-scores. Plus we only need one set of tables and formulas instead of different ones for every possible mean and standard deviation combination. Its like having a universal measurement system that works for everything."
      ],
      "metadata": {
        "id": "uesT5WYVVNI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?**"
      ],
      "metadata": {
        "id": "eGFlfwEgVNGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Basically it says that if you take a bunch of samples from ANY population (could be totally skewed, weird shaped, whatever) and calculate the average of each sample, those averages will form a normal distribution.\n",
        "\n",
        "Even if the original data looks nothing like a bell curve! The only requirement is that your sample size is big enough, usually around 30 or more.\n",
        "\n",
        "This is huge because it means I can use all the normal distribution techniques even when my original data is messy. Like individual salaries are really skewed because some people make way more than others, but if I take samples of 50 people each and look at the average salaries, those averages will be normally distributed."
      ],
      "metadata": {
        "id": "FfMlR7WsVNDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. How does the Central Limit Theorem relate to the normal distribution?**"
      ],
      "metadata": {
        "id": "HySvnyxuVNAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CLT explains why we see normal distributions everywhere in statistics. Most of the time we're working with averages or means of some kind, and CLT guarantees those will be normal.\n",
        "\n",
        "So techniques like confidence intervals and hypothesis tests work because they assume sample means are normally distributed, which CLT makes true. Even if my original data is weird and bumpy, once I start looking at sample averages, everything smooths out into that familiar bell shape."
      ],
      "metadata": {
        "id": "MT_GiKvgVM98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is the application of Z statistics in hypothesis testing?**"
      ],
      "metadata": {
        "id": "3CtBXeOqVM7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Z statistics help figure out if your sample results are actually significant or just random chance.\n",
        "\n",
        "Say I think a coin is biased and I flip it 100 times and get 65 heads. The z-statistic tells me how many standard deviations away from 50 (what I'd expect for a fair coin) my result of 65 is.\n",
        "\n",
        "If that z-value is extreme enough, like beyond +- 1.96, then I can say this probably didn't happen by luck and reject my null hypothesis that the coin is fair."
      ],
      "metadata": {
        "id": "ADFr9ndtVM4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. How do you calculate a Z-score, and what does it represent?**"
      ],
      "metadata": {
        "id": "3heJp6-1dmsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Z-score formula is: (your value - mean) / standard deviation.\n",
        "\n",
        "This tells you how many standard deviations away from the mean your value is.\n",
        "\n",
        "So z-score of 0 means exactly average, +2 means 2 standard deviations above average, -1.5 means 1.5 standard deviations below average.\n",
        "\n",
        "The useful thing is you can compare totally different measurements this way. Like I can compare how tall I am relative to other people with how well I did on a test relative to my class, because both get converted to the same z-score scale."
      ],
      "metadata": {
        "id": "xrsc8IEkVM1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What are point estimates and interval estimates in statistics?**"
      ],
      "metadata": {
        "id": "0JmVvjtmVMy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Point estimate is just your best single guess for a population parameter based on sample data.\n",
        "\n",
        "Like if sample mean is 73.2, that's my point estimate for population mean.\n",
        "\n",
        "But point estimates don't tell you how confident you should be. Interval estimates give you a range plus confidence level. Instead of saying \"the answer is 73.2\" I'd say \"I'm 95% confident the real answer is between 71.8 and 74.6\". The width tells you how precise your estimate is - narrow interval means you're pretty sure, wide interval means lots of uncertainty."
      ],
      "metadata": {
        "id": "ypnsCZ-AVMwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What is the significance of confidence intervals in statistical analysis?**"
      ],
      "metadata": {
        "id": "qRWg9gp0VMtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Confidence intervals are important because they admit uncertainty instead of pretending we know exact values.\n",
        "\n",
        "A 95% confidence interval means if I repeated this sampling process many times, about 95% of the intervals would contain the true population value. This helps with decision making because I know not just my best guess but also how reliable it is.\n",
        "\n",
        "If two groups have overlapping confidence intervals, I can't really say they're different. If intervals don't overlap, there's probably a real difference."
      ],
      "metadata": {
        "id": "BVjqJiqJVMqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What is the relationship between a Z-score and a confidence interval?**"
      ],
      "metadata": {
        "id": "wGawTPobVMng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The z-score controls how wide the confidence interval will be.\n",
        "\n",
        "For 95% confidence I use z=1.96, for 99% confidence I use z=2.58. Higher confidence needs bigger z-score which makes wider interval.\n",
        "\n",
        "It's a trade-off - you can have high confidence or narrow interval, but not both unless you get more data. The formula is usually sample mean +- (z-score × standard error), so bigger z-score means wider interval."
      ],
      "metadata": {
        "id": "BE5b7jjfVMkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. How are Z-scores used to compare different distributions?**"
      ],
      "metadata": {
        "id": "cvnCiuqdVMh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Z-scores let you compare things measured on different scales.\n",
        "\n",
        "Say I scored 85 on math test where class average was 78 with SD=6, giving z-score of (85-78)/6 = 1.17.\n",
        "\n",
        "My friend scored 92 on different test where average was 88 with SD=4, giving z-score of (92-88)/4 = 1.0.\n",
        "\n",
        "Even though her/his raw score was higher, my z-score was higher so I actually did better relative to my class. This standardization works for comparing any kind of performance across different contexts."
      ],
      "metadata": {
        "id": "S_cMeR6UVMPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What are the assumptions for applying the Central Limit Theorem?**"
      ],
      "metadata": {
        "id": "LHt9CpcUhXPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For CLT to work you need independent observations, random sampling, and large enough sample size. Usually people say 30 minimum but if population is really skewed you might need 50 or more.\n",
        "\n",
        "Also if you're sampling without replacement, population should be at least 10 times bigger than sample. When these conditions aren't met, CLT might not work and your sample means won't necessarily be normal."
      ],
      "metadata": {
        "id": "to2jsrPlhXJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. What is the concept of expected value in a probability distribution?**"
      ],
      "metadata": {
        "id": "s4M8aSyMhXDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Expected value is the average you'd get if you repeated an experiment many times. Calculate it by multiplying each outcome by its probability and adding up. Like fair die has expected value of (1×1/6) + (2×1/6) + ... + (6×1/6) = 3.5\n",
        "\n",
        "You can never actually roll 3.5 but that's the long-run average. In gambling, negative expected value means house has advantage. In business, helps evaluate investments by considering all possible outcomes weighted by probabilities."
      ],
      "metadata": {
        "id": "zpPRd-B5hW9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. How does a probability distribution relate to the expected outcome of a random variable?**"
      ],
      "metadata": {
        "id": "866X9sI_hW1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Probability distribution shows all possible outcomes and their probabilities. Expected value takes that info and gives you one summary number - the average outcome.\n",
        "\n",
        "Distribution is like detailed weather forecast showing different possible temperatures, expected value is like average expected temperature. You need both - distribution helps understand risk and plan for scenarios, expected value gives simple number for quick comparisons."
      ],
      "metadata": {
        "id": "VeqdYUmChWW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment completed by Arghadeep Misra"
      ],
      "metadata": {
        "id": "MWZgLeXqh-hM"
      }
    }
  ]
}